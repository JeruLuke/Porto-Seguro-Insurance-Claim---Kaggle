{
  "cells": [
    {
      "metadata": {
        "_uuid": "4610384545228386f777a343010b383cf21ce60a"
      },
      "cell_type": "markdown",
      "source": "more about kinetic features  developed  by Daia Alexandru    here  on the next  blog  please  read  last article :\nhttps://alexandrudaia.quora.com/"
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "7050fb8fbcc08642a5664980cccc55fffd732f91",
        "_cell_guid": "37185c37-2789-46a8-99c0-9bca4a09238a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5dc29a274368e99ea1c56959783d764925c76dbd",
        "_cell_guid": "67d4a036-dcab-41c2-ae48-56ae6fb1cb6b",
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n# Read data\ntrain=pd.read_csv('../input/train.csv')\ntest=pd.read_csv('../input/test.csv')\n\n\n# Kinetic function\ndef  kinetic(row):\n    probs=np.unique(row,return_counts=True)[1]/len(row)\n    kinetic=np.sum(probs**2)\n    return kinetic\n    \n# Creating Kinetic for train    \nfirst_kin_names=[col for  col in train.columns  if '_ind_' in col]\nsubset_ind=train[first_kin_names]\nkinetic_1=[]\nfor row in range(subset_ind.shape[0]):\n    row=subset_ind.iloc[row]\n    k=kinetic(row)\n    kinetic_1.append(k)\n\nsecond_kin_names= [col for  col in train.columns  if '_car_' in col and col.endswith('cat')]\nsubset_ind=train[second_kin_names]\nkinetic_2=[]\nfor row in range(subset_ind.shape[0]):\n    row=subset_ind.iloc[row]\n    k=kinetic(row)\n    kinetic_2.append(k)\n\nthird_kin_names= [col for  col in train.columns  if '_calc_' in col and  not col.endswith('bin')]\nsubset_ind=train[second_kin_names]\nkinetic_3=[]\nfor row in range(subset_ind.shape[0]):\n    row=subset_ind.iloc[row]\n    k=kinetic(row)\n    kinetic_3.append(k)\n\nfd_kin_names= [col for  col in train.columns  if '_calc_' in col and  col.endswith('bin')]\nsubset_ind=train[fd_kin_names]\nkinetic_4=[]\nfor row in range(subset_ind.shape[0]):\n    row=subset_ind.iloc[row]\n    k=kinetic(row)\n    kinetic_4.append(k)\n\ntrain['kinetic_1']=np.array(kinetic_1)\ntrain['kinetic_2']=np.array(kinetic_2)\ntrain['kinetic_3']=np.array(kinetic_3)\ntrain['kinetic_4']=np.array(kinetic_4)\n\n# Creating Kinetic for test\nfirst_kin_names=[col for  col in test.columns  if '_ind_' in col]\nsubset_ind=test[first_kin_names]\nkinetic_1=[]\nfor row in range(subset_ind.shape[0]):\n    row=subset_ind.iloc[row]\n    k=kinetic(row)\n    kinetic_1.append(k)\n\nsecond_kin_names= [col for  col in test.columns  if '_car_' in col and col.endswith('cat')]\nsubset_ind=test[second_kin_names]\nkinetic_2=[]\nfor row in range(subset_ind.shape[0]):\n    row=subset_ind.iloc[row]\n    k=kinetic(row)\n    kinetic_2.append(k)\n\nthird_kin_names= [col for  col in test.columns  if '_calc_' in col and  not col.endswith('bin')]\nsubset_ind=test[second_kin_names]\nkinetic_3=[]\nfor row in range(subset_ind.shape[0]):\n    row=subset_ind.iloc[row]\n    k=kinetic(row)\n    kinetic_3.append(k)\n\nfd_kin_names= [col for  col in test.columns  if '_calc_' in col and  col.endswith('bin')]\nsubset_ind=test[fd_kin_names]\nkinetic_4=[]\nfor row in range(subset_ind.shape[0]):\n    row=subset_ind.iloc[row]\n    k=kinetic(row)\n    kinetic_4.append(k)\n\ntest['kinetic_1']=np.array(kinetic_1)\ntest['kinetic_2']=np.array(kinetic_2)\ntest['kinetic_3']=np.array(kinetic_3)\ntest['kinetic_4']=np.array(kinetic_4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d14bac39122629d48d43aa51d6040da5ea0c5e53",
        "_cell_guid": "2dad208d-f1a9-4410-b4ff-f394ece28eed"
      },
      "cell_type": "markdown",
      "source": "# Correlation matrix"
    },
    {
      "metadata": {
        "_uuid": "fd103eb3208db1068e383346cf22d2acd332510c",
        "_cell_guid": "4a6b4e3d-306f-4e79-945f-82ff6be9079f",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sns.set(style=\"white\")\n\n# Compute the correlation matrix\ncorr = train.corr()\n\n# Set up the matplotlib figure dimensions\nf, ax = plt.subplots(figsize=(20, 25))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e8712d2349e1e4583a59673228be90d0f5d2c4ef",
        "_cell_guid": "c0839979-6194-4d10-968b-b4b08bace252"
      },
      "cell_type": "markdown",
      "source": ""
    },
    {
      "metadata": {
        "_uuid": "e636aa9347987e9fa8c2844553a03c9c54324134",
        "_cell_guid": "08477d20-53a0-4ea6-a803-22a604667536"
      },
      "cell_type": "markdown",
      "source": "# Feature Importance"
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "b54c8d9ca9a50e22737ebe510b4dadd4b1b05ddf",
        "_cell_guid": "345b585b-7aac-48af-a68a-eff2ec0b9fb7",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def gini(actual, pred):\n    assert (len(actual) == len(pred))\n    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n    totalLosses = all[:, 0].sum()\n    giniSum = all[:, 0].cumsum().sum() / totalLosses\n\n    giniSum -= (len(actual) + 1) / 2.\n    return giniSum / len(actual)\n\ndef gini_normalized(a, p):\n    return gini(a, p) / gini(a, a)\n\ndef gini_xgb(preds, dtrain):\n    labels = dtrain.get_label()\n    gini_score = gini_normalized(labels, preds)\n    return 'gini', gini_score",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "39aad5a3ad84cb82f692db6ef26633a0e1cd3c27",
        "_cell_guid": "bed13b37-7c5b-4656-9763-4533eed4dffd",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\n\n# Get X and y\nX = train.drop(['id', 'target'], axis=1).values\ny = train['target'].values\n\nparams = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, \n          'objective': 'binary:logistic', 'eval_metric': 'auc', 'seed': 99, 'silent': True}\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=99)\n\nd_train = xgb.DMatrix(X_train, y_train)\nd_valid = xgb.DMatrix(X_valid, y_valid)\n\nwatchlist = [(d_train, 'train'), (d_valid, 'valid')]\n\nmdl = xgb.train(params, d_train, num_boost_round=2000, evals=watchlist,\n          early_stopping_rounds=100, feval=gini_xgb,\n          maximize=True, verbose_eval=500)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0991bffa04c6bc63a7234263058060473b26bc8a",
        "_cell_guid": "8bcffa8d-8520-47d5-82ba-10a827867635",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\n# Feature names\nfeature_names = list(train.drop(['id', 'target'], axis=1).keys())\n\n# Importances \nimportances = (sorted(map(lambda x: (int(x[0][1:]), x[1]), mdl.get_fscore().items()), key=lambda x: x[0]))\n\n# Some features may not appear, need to organize\nfeature2importance = {}\nfor feat, x in importances:\n    feature2importance[feat] = x\n\nfeature_names2importances = []\nfor i, x in enumerate(feature_names):\n    if i in feature2importance:\n        feature_names2importances.append((x, feature2importance[i]))\n    else:\n        feature_names2importances.append((x, 0))\n        \ndf = pd.DataFrame(sorted(feature_names2importances, key=lambda x: x[1]), columns=['feature', 'fscore'])\n_ = df.plot(title=\"XGB's feature fscores\", kind='barh', x='feature', y='fscore', legend=False, figsize=(10, 25))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "15a75d05b6255d8215cd9d1a092405573a9acdc6",
        "_cell_guid": "9731744c-6be3-4d8a-b300-3d0723b3745d",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\n\n# Get rid of NaN -> replace with median value\nfor key in train.keys():\n    train[key].fillna(train[key].median(), inplace=True)\n# Get X and y\nX = train.drop(['id', 'target'], axis=1).values\ny = train['target'].values\n\nmdl = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42)\n_ = mdl.fit(X, y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a6f1da9a2ca9ca27e7ca76ec6a7764a7c6b5e5f3",
        "_cell_guid": "4976cb06-9f73-4a09-b7e2-e31560c36be1",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Feature names\nfeature_names = list(train.drop(['id', 'target'], axis=1).keys())\n\n# Importances and standard deviation\nimportances = mdl.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in mdl.estimators_], axis=0)\n\nassert len(importances) == len(feature_names)\n\ndf = pd.DataFrame(sorted(zip(feature_names, importances, std), key=lambda x: x[1]), \n                  columns=['feature', 'fscore', 'std'])\n_ = df.plot(title=\"Random Forest's feature importances\", kind='barh', x='feature', y='fscore', yerr='std',\n            legend=False, figsize=(10, 25))",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}